# Multimodal Emotion & Wellbeing Analysis  
*(Face Â· Text Â· Voice â€” Deep Learning + HuggingFace)*

## ğŸŒŸ Overview

This project is a **full multimodal emotionâ€‘analysis system** supporting:

### âœ… **1. Facial Emotion Recognition (PyTorch Â· ResNetâ€‘18)**  
- Uses combined **FER2013 + RAFâ€‘DB** dataset  
- Gradâ€‘CAM visualization  
- Face detection (OpenCV Haar Cascade)  
- Produces emotion + wellbeing indicator  

### âœ… **2. Text Emotion Analysis (HuggingFace)**  
- Uses a **local textâ€‘classification model** (DistilBERT fineâ€‘tuned) &  **hf-local model**
- Works fully offline  
- Produces emotion + tone probabilities  
- Integrates into wellbeing scoring  

### âœ… **3. Voice Tone Emotion Analysis (Audio CNN or HF Model)**  
- Two modes:
  - **Fast Mode** â†’ Local CNN classifier  
  - **Accurate Mode** â†’ Offline HuggingFace Wav2Vec2 model  
- Returns emotion + prosodyâ€‘based emotional tone  

### ğŸ¯ **Wellbeing Insight Engine**
Tracks recent predicted emotions (sliding window of 50 samples) and generates:
- Positivity trend  
- Negative spikes  
- Stability rating  
- Simple nonâ€‘clinical wellbeing indicator  

> âš ï¸ **Disclaimer:**  
> This project does **NOT** diagnose mental health or medical conditions.  
> It provides informational insights only.

---

# ğŸ“Œ Features

## ğŸ”¹ Facial Emotion Features
- ResNetâ€‘18â€‘based classifier  
- Preprocessing (normalization, resizing)  
- Gradâ€‘CAM heatmaps  
- Realâ€‘time webcam mode (`/live`)

## ğŸ”¹ Text Emotion Features
- Local HuggingFace emotion model  
- Supports multiple emotions (happy, sad, anger, fear, neutral, etc.)  
- Lightweight inference  
- Can process any freeâ€‘text description  

---

## ğŸ”¹ Voice Emotion Features
### ğŸ™ï¸ Fast Mode (Local CNN)
- MFCCâ€‘based  
- Lightweight & fast  

### ğŸ™ï¸ Accurate Mode (HF Wav2Vec2)
- Works offline  
- Better accuracy  
- Slower inference  

Example Output:
```
Emotion: angry
Probabilities: { angry: 0.74, sad: 0.10, neutral: 0.08, ... }
```

---

# ğŸ“ Project Structure

```
facial-emotion-wellbeing/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ config.py
â”œâ”€â”€ mental_health_insights.py
â”œâ”€â”€ merge_datasets.py
â”œâ”€â”€ data/
|   â”œâ”€â”€ fer2013/ (Face)
|   â”œâ”€â”€ rafdb/ (Face)
|   â”œâ”€â”€ savee/ (Audio)
|   â”œâ”€â”€    / (Text)
|
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ emotion_model.py
â”‚   â”œâ”€â”€ hf_text_model
|   â”œâ”€â”€ hf_audio_model
|   â”œâ”€â”€ trained_model.pth
|   â””â”€â”€ audio_model.pth
â”‚
â”œâ”€â”€ multimodal/
â”‚   â”œâ”€â”€ text_emotion.py
|   â”œâ”€â”€ audio_emotion.py
â”‚   â””â”€â”€ audio_emotion.py
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ results/   â† stores GradCAM & original images
â”‚   â””â”€â”€ audio/     â† stores uploaded/recorded audio
|
â”œâ”€â”€ inference/
|   â”œâ”€â”€ predict_singl.py
|
â”œâ”€â”€ training/
|   â”œâ”€â”€ evaluate.py
|   â”œâ”€â”€ evaluate_audio.py
|   â”œâ”€â”€ evaluate_text.py
|   â”œâ”€â”€ train.py
|   â”œâ”€â”€ train_audio.py
|   â”œâ”€â”€ train_text.py
|   â”œâ”€â”€ utils.py    
|
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ upload.html
â”‚   â”œâ”€â”€ text.html
â”‚   â”œâ”€â”€ audio.html
â”‚   â”œâ”€â”€ live.html
|   â”œâ”€â”€ text_unavailable.py
â”‚   â”œâ”€â”€ result.html
â”‚   â”œâ”€â”€ result_text.html
â”‚   â””â”€â”€ result_audio.html
â”‚
â””â”€â”€ README.md
```

---

# ğŸš€ Installation

```
git clone <repo-url>
cd 
pip install -r requirements.txt
```

---

# â–¶ï¸ Run the Application

```
python app.py
```

App runs at:

```
http://127.0.0.1:5000
```

---

# ğŸ§  Wellbeing Indicator Logic

Based on last 50 emotions:

- Repeated **negative emotion spikes** â†’ â€œLow stabilityâ€
- Balanced mix of emotions â†’ â€œNeutral / Stableâ€
- Majority positive emotions â†’ â€œGood wellbeing trendâ€
- Sudden shifts â†’ â€œVolatile emotional patternâ€

Returns:
```
{
  "wellbeing_indicator": "Medium Concern",
  "insight_text": "Recent patterns show elevated sadness and anger..."
}
```

---

# ğŸ“¦ Datasets Used (Face Model)

### FER2013 + RAFâ€‘DB (basic)
Both merged into 7 emotions:
```
angry, disgust, fear, happy, sad, surprise, neutral
```

Dataset folder structure:
```
dataset/
  train/
  val/
  test/
```

---

# ğŸ“ License
MIT License 

---

# â¤ï¸ Credits
- PyTorch  
- HuggingFace Transformers  
- OpenCV  
- FER2013 dataset  
- RAFâ€‘DB dataset  

---

If you want, I can also generate:  
âœ” Badges  
âœ” Screenshots  
âœ” Model architecture diagrams  
âœ” API route documentation

